# Zusammenfassung

Durch die Allgegenwart von Informationstechnologien ist auch in den Sozialwissenschaften die Bedeutung digitaler Prozessdaten enorm gewachsen.
Die adäquate Analyse solcher aus der Interaktion mit sozio-technischen Systemen gewonnen Daten erfordert entsprechendes Hintergrundwissen sowie spezifische praktische Fähigkeiten, die dieser Kurs vermitteln möchte.
Durch Übungen und Anwendungsbeispiele sollen Möglichkeiten, aber auch Probleme neuer digitaler Datenquellen aufgezeigt werden.
Der Workshop führt zunächst in die Programmiersprache Python ein.
Danach werden verschiedene Methoden der Datenextraktion und schließlich auch die speziellen Herausforderungen der Aufbereitung und Analyse dieser Datentypen behandelt.


# Ablauf

Der Workshop ist auf ca. 5 Tage ausgelegt.
Dies umfasst auch Pausen und das Mittagsessen, was eine reine Übungszeit von ca. 6 Stunden pro Tag ergibt.
Die Abfolge der Themen soll flexibel genug sein um die Bedürfnisse und spezifischen Forschungsfragen der individuellen Teilnehmer zu berücksichtigen.

1. **14.03.2022: Computational Social Science.**  
   Einführung in die technische Infrastruktur und begleitete Installation benötigter Programmpakete sowie die Vorstellung grundlegender Programmiertechniken und Vorgehensweisen im Rahmen der Computational Social Science (CSS).
   Im Rahmen des Kurses wird hauptsächlich die [Anaconda Python](https://docs.anaconda.com/anaconda/) Distribution verwendet werden.
    * 13:00–15:00: Das Medium Data Problem in CSS.
    * 15:15–16:15: Anaconda Distribution und `conda` Package-Management. 
    * 16:30–17:30: Jupyter Notebook and JupyterLab als grundlegende Infrastruktur. 
    * 17:30–18:00: Wissenschaftliches Schreiben in Markdown und Pandoc.
3. **15.03.2022: Python.**  
   Ausführliche Besprechung von Pythons Syntax, primitiven und weiterführenden Datentypen sowie relevanter Python Module und Bibliotheken für die Forschung.
    * 09:00–10:00: Grundlegende Datentypen und Pythons Typenhierarchie.
    * 10:15–11:15: Container Objekte.
    * 11:30–12:30: Schleifen und logische Bedingungen.
    * 14:00–15:00: Funktionen und Klassen.
    * 15:15–16:15: `pandas`: DataFrames und Serien.
    * 16:30–17:30: Scientific Computing: Einführung in den SciPy Stack.
    * 17:30–18:00: Offene Fragen.
5. **16.03.2022: APIs und Webscraping.**  
   Umgang mit webbasierten APIs (Application Programming Interfaces) im Zuge der Datenerhebung.
   Generelles Vorgehen beim Webscraping, dem rekursiven Download von Webressourcen und der Extraktion von Informationen aus HTML-Dokumenten.
    * 09:00–10:00: URLs als Basis von Client Server Interaktion.
    * 10:15–11:15: Einsatz von Web-APIs.
    * 11:30–12:30: Web-Crawling.
    * 14:00–15:00: HTML Dokumente.
    * 15:15–16:15: Web-Scraping mit `BeautifulSoup`.
    * 16:30–17:30: Scraping und Crawling
    * 17:30–18:00: Offene Fragen.
6. **17.03.2022: Datenaufbereitung.**  
   Aufbereitung von Daten und die Extraktion von Informationen aus Rohdaten, wie z.B. Texten.
   Als zentrale Technik wird hier die Arbeit mit regulären Ausdrücken vorgestellt und eingeübt.
    * 09:00–10:00: Reguläre Ausdrücke I.
    * 10:15–11:15: Reguläre Ausdrücke II.
    * 11:30–12:30: Reguläre Ausdrücke und Text Mining in `pandas`.
    * 14:00–15:00: Data Munging: Von den Rohdaten zum DataFrame.
    * 15:15–16:15: Der Einsatz von Wget für rekursive Downloads.
    * 16:30–17:30: Selenium: Webdriving und Spoofing.
    * 17:30–18:00: Offene Fragen.
8. **18.03.2022: Data management und analysis.**  
   Techniken des Umgangs mit Daten und deren Archivierung.
   Wie ist die Datenqualität von prozessgenerierten Daten zu beurteilen? 
   Weiteres Thema ist die Vorstellung von Analysetechniken, wie beispielsweise dem Machine Learning, und der Verweis auf weiterführende Ressourcen zum Selbststudium. 
    * 09:00–10:00: Datenpersistenz: Datenbanken und Datenformate.
    * 10:15–11:15: Fragen der Datenqualität.
    * 11:30–12:30: Statistische Modellierung in Python.
    * 14:00–15:00: Machine Learning.
